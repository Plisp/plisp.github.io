<?xml version="1.0"?>
<feed xmlns="http://www.w3.org/2005/Atom"> <title>(gensym)</title> <link href=""/> <link type="application/atom+xml" rel="self" href="/atom.xml"/> <updated>Wed, 10 May 2023 14:23:16 +0000</updated> <author> <name>plisp</name> </author> <entry> <link type="text/html" rel="alternate" href="/posts/Regular-number-sets.html"/> <title>Regular number sets</title> <published>2023-04-29 12:26:46</published> <updated>2023-04-29 12:26:46</updated> <author> <name>plisp</name> <uri></uri> </author> <content type="html">&lt;p&gt;Have you ever wondered why you can&#039;t match powers of 2 with a regex?
Well I didn&#039;t... at least until I took Theory of Computation and went down this
number-theoretical rabbithole on a whim.
Let&#039;s uncover some cool structure!&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;This journey started when I noticed certain sets like the naturals modulo &lt;code&gt;k&lt;/code&gt;
were &lt;a href=&quot;https://en.wikipedia.org/wiki/Regular_language&quot; &gt;regular languages&lt;/a&gt;
in various bases and wondered to my complexity lecturer
which unary number sets could be recognised or &#039;computed&#039; by a
&lt;a href=&quot;https://en.wikipedia.org/wiki/Deterministic_finite_automaton&quot; &gt;DFA&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Evidently he knew something I didn&#039;t and thought I should figure it out for myself,
since his answer was obliquely a question:
are the unary square numbers a regular language?
I quickly worked out that it was not, and proved a characterization of
regular unary sets as those which had eventually periodic differences between
their numerically-ordered elements (proof left to reader).&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/base-dfa-squares.jpg&quot;&gt; &lt;/p&gt;

&lt;p&gt;A natural direction was then to ask the same question for higher number bases.
Let&#039;s consider numbers represented in base &lt;code&gt;b&lt;/code&gt; as strings of &lt;code&gt;0..b-1&lt;/code&gt; with
least significant digits first (this choice is arbitrary, since
regular languages are closed under reversal of their strings).&lt;/p&gt;

&lt;p&gt;As a first step, I noticed that by duplicating the DFA for a unary language and
adding transitions as drawn, you could recognise the same set of numbers in any
other base. Let&#039;s express this as &lt;code&gt;B(0) âŠ† B(k)&lt;/code&gt; for any &lt;code&gt;k &amp;gt; 1&lt;/code&gt;, suggesting that
the representable sets in &lt;code&gt;0&lt;/code&gt; are contained within those of any logarithmic base &lt;code&gt;k&lt;/code&gt;.
You might notice that the opposite is not true, namely powers of 2 clearly do not
have eventually periodic differences and so cannot be computed by a unary DFA.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/base-dfa-construction.jpg&quot;&gt; &lt;/p&gt;

&lt;p&gt;Generalizing, it&#039;s fairly clear that the sets computable in base &lt;code&gt;b&lt;/code&gt; remain
the same even if we raise the base to an arbitrary power &lt;code&gt;b^k&lt;/code&gt;. This can be done
by switching every &lt;code&gt;k&lt;/code&gt; transitions in the base-&lt;code&gt;b&lt;/code&gt; DFA
for a single transition in the &lt;code&gt;b^k&lt;/code&gt; alphabet and vice versa, so &lt;code&gt;B(b) = B(b^k)&lt;/code&gt;.
More subtly, it seems that bases corresponding to different powers &lt;code&gt;c^j&lt;/code&gt; cannot
express the same regular sets, in particular the powers of&lt;code&gt;b&lt;/code&gt;.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/base-dfa-structure.jpg&quot;&gt; &lt;/p&gt;

&lt;p&gt;Now let&#039;s try to formalize the original question a little in terms of this intuition.
Since regexes (of the non-Perl kind) are equivalent to regular languages,
we can ask whether the powers of 2 are regular over the base-10 alphabet.
That is, can we construct a DFA which accepts exactly strings of 0-9
corresponding to powers of 2.&lt;/p&gt;

&lt;p&gt;Intuitively, this should be false, as 2 and 10 are not powers of a common base!
Let&#039;s consider the problem through the clever exact characterization of regular languages
known as the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Myhill%E2%80%93Nerode_theorem&quot; &gt;Myhill-Nerode theorem&lt;/a&gt;.
To prove that the powers of 2 are not regular, we need a infinite number of prefixes
of strings in the language, that differ as to whether they&#039;re in the language when
you append some well-chosen string to any pair.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/base-dfa-proof.jpg&quot;&gt; &lt;/p&gt;

&lt;p&gt;A natural choice is to let the prefixes be the rings (modulo powers of 10)
formed by repeating sequences of last digits, which clearly occur in an
infinite number of powers of 2, so should be distinguishable (if the goal is true),
as argued above.
Generalizing to the full claim about arbitrary bases is left to the reader ;).&lt;/p&gt;

&lt;p&gt;N.B. there&#039;s a small caveat that when proving the set &lt;code&gt;a^n&lt;/code&gt; is non-regular in base
&lt;code&gt;b&lt;/code&gt; where &lt;code&gt;a&lt;/code&gt; contains all prime factors of &lt;code&gt;b&lt;/code&gt; (possibly to a smaller power),
all prefixes will be zeroes, but this is still enough to see that some pair is
distinguishable iff they are powers of the same base.
Otherwise we may assume some prime factor in the base does not occur in the set of
powers being represented and this gives increasingly large rings (for sufficiently
long positive prefixes, multiplying by &lt;code&gt;a&lt;/code&gt; will produce a larger ring).&lt;/p&gt;
</content> </entry><entry> <link type="text/html" rel="alternate" href="/posts/Intro-to-fuzzing-with-AFL.html"/> <title>Intro to fuzzing with AFL</title> <published>2022-07-04 14:31:44</published> <updated>2022-07-04 14:31:44</updated> <author> <name>plisp</name> <uri></uri> </author> <content type="html">&lt;p&gt;Fuzzing is essentially testing code with lots random inputs to hopefully get a crash if the code is incorrect.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/afl-lop.png&quot;&gt; &lt;/p&gt;

&lt;p&gt;AFL (American Fuzzy Lop ^ thanks wikipedia) is a bit smarter than the average jank script though, being a &lt;em&gt;genetic&lt;/em&gt; fuzzer which uses the compiler&#039;s knowledge of branches (&lt;code&gt;if&lt;/code&gt;/&lt;code&gt;while&lt;/code&gt;) to aggressively root out new paths through code, keeping &amp;quot;interesting&amp;quot; inputs for further mutation in some loose analogy to evolutionary success. This also takes some extra setup, but is
&lt;a href=&quot;https://www.sqlite.org/src/info/a59ae93ee990a55&quot; &gt;extremely&lt;/a&gt;
&lt;a href=&quot;https://marc.info/?l=openssl-dev&amp;m=145890788100691&amp;w=2&quot; &gt;effective&lt;/a&gt;
in practice for finding elusive bugs.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h2&gt;Setup&lt;/h2&gt;

&lt;p&gt;First grab the &lt;a href=&quot;https://lcamtuf.coredump.cx/afl/releases/afl-latest.tgz&quot; &gt;code&lt;/a&gt;,
extract it using &lt;code&gt;tar xf afl-latest.tgz&lt;/code&gt; and compile it with a single &lt;code&gt;make&lt;/code&gt; in the source directory.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ tar xf afl-latest.tgz

$ cd afl-2.52b # replace with the version you got

$ ls
Makefile             afl-cmin       afl-tmin.c    docs          qemu_mode
QuickStartGuide.txt  afl-fuzz.c     afl-whatsup   experimental  test-instr.c
README               afl-gcc.c      alloc-inl.h   hash.h        testcases
afl-analyze.c        afl-gotcpu.c   config.h      libdislocator types.h
afl-as.c             afl-plot       debug.h       libtokencap
afl-as.h             afl-showmap.c  dictionaries  llvm_mode

$ make
[*] Checking for the ability to compile x86 code...
[+] Everything seems to be working, ready to compile.
...&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The next step is to write a test program which reads from standard input and runs a number of operations which you&#039;re interested in testing. With thorough checking of both operation results and internal structures with &lt;code&gt;assert()&lt;/code&gt;, any incorrect behavior will result in a crash, notifying the fuzzer. Be warned: this also includes any errors while reading input, which should be handled gracefully by the test program without crashing as AFL &lt;em&gt;will&lt;/em&gt; feed it weird stuff.&lt;/p&gt;

&lt;p&gt;Here&#039;s a sample session from some Set testing code - note I inputted everything after the &lt;code&gt;&amp;gt;&lt;/code&gt; prompts, to run certain set operations like display, insertion, set floor, etc..&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ ./program
&amp;gt;s
Set:{0} cur item:0
&amp;gt;+ 3
&amp;gt;s
Set:{0, 3} cur item:0
&amp;gt;&amp;gt;
&amp;gt;s
Set:{0, 3} cur item:3
&amp;gt;f 2
item 2, set floor 0
&amp;gt;c 2
item 2, set ceil 3
&amp;gt;q&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Test it a little manually to make sure your reference works and then create a directory to store some sample inputs in. I called it &lt;code&gt;cases&lt;/code&gt; and put a couple commands in a file like this:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ cat cases/test
+ 420
+ -12
s
n
&amp;gt;
f 3
c 0
q&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now let the fuzzer install its branch tracking code in the program by compiling with:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ AFL_HARDEN=1 afl-clang -fsanitize=undefined -fsanitize-undefined-trap-on-error [files/flags...]&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This additionally enables clean crashes on subtle buffer overflows and undefined behavior issues
(&lt;a href=&quot;https://clang.llvm.org/docs/index.html&quot; &gt;sanitizers&lt;/a&gt; are a must when writing C in general.
You can also enable address-sanitizer if you have a high enough process memory limit - I didn&#039;t - but &lt;code&gt;AFL_HARDEN&lt;/code&gt; enables &lt;code&gt;_FORTIFY_SOURCE=2&lt;/code&gt; which should achieve a similar effect).&lt;/p&gt;

&lt;h2&gt;Fuzzing&lt;/h2&gt;

&lt;p&gt;Now using a clever fuzzer is like a game, where you have to fix bugs found by an AI determined to break your code. There&#039;s still thinking and facepalming involved, but it can be very rewarding!&lt;/p&gt;

&lt;p&gt;To start, run&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ afl-fuzz -i cases -o fuzz-output ./program&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;and some cool colorful information should appear... and oh no there&#039;s a crash?&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/afl-fail.png&quot;&gt; &lt;/p&gt;

&lt;p&gt;Immediately stop the fuzzing with control+c and ask AFL to &lt;em&gt;minimise&lt;/em&gt; the failure case using its heuristics (choosing an older input file in the crashes directory)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ afl-tmin -i fuzz-output/crashes/[id\:000...] -o case -- ./program&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will write a simplified input sample into &lt;code&gt;case&lt;/code&gt; which will make your program crash. Now you can debug the issue by feeding your program the input in a debugger or valgrind as usual. Then, recompile with your fixes and keep fuzzing until the &lt;code&gt;cycles done:&lt;/code&gt; meter in the top right corner is yellow; preferably green, but in my experience AFL finds most bugs in simple programs within minutes.&lt;/p&gt;

&lt;p&gt;I personally found this workflow more satisfying and effective than collecting a large corpus of failure cases, as a single error often leads to many related issues which can be fixed in one go. Of course, you might need to recompile and lose some fuzzing progress, but that&#039;s usually not a consideration unless fuzzing a large codebase.&lt;/p&gt;

&lt;h2&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;Genetic fuzzing with AFL often finds very elusive bugs which are difficult to detect without formal verification, which can be somewhat error-prone in itself. Combined with tools that can trigger crashes early, the combination can be a lifesaver especially when writing C.&lt;/p&gt;

&lt;p&gt;Good luck and happy fuzzing!&lt;/p&gt;
</content> </entry><entry> <link type="text/html" rel="alternate" href="/posts/Terminals-ARE-NOT-GUI.html"/> <title>Terminals ARE NOT GUI</title> <published>2022-01-16 16:02:09</published> <updated>2022-01-16 16:02:09</updated> <author> <name>plisp</name> <uri></uri> </author> <content type="html">&lt;p&gt;Unless you&#039;re dealing solely with ascii, which is typically a naive assumption in our 
Unicode world and &lt;em&gt;especially&lt;/em&gt; in the realm of text editing widgets, terminal emulators
should be avoided for the dusty VT100 relics they are.&lt;/p&gt;

&lt;p&gt;Not only is input handling unbelievably botched, consistent text rendering
is impossible across terminals.&lt;/p&gt;

&lt;!--more--&gt;

&lt;p&gt;To understand the unfixable brokenness we must look inside the terminal:&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/terminal.jpeg&quot;&gt; &lt;/p&gt;

&lt;p&gt;The original terminals were physical devices capable of displaying a simple
grid of characters, and so the textual terminal interfaces developed mapped
elegantly to the displays of the time (much prior to Unicode).
However when true GUI caught on, this design meant terminal drivers needed to be
developed with the sole purpose of emulating a physical terminal to support shells
and other programs predating graphical environments, which relied on line buffering
and catching special characters such as ctrl+c.
A UNIXy kernel typically exposes this functionality
through pseudoterminals (PTYs), where bytes written between the
graphical terminal emulator and program can be first mediated by the OS driver.&lt;/p&gt;

&lt;p&gt;Ironically &amp;quot;terminal user interfaces&amp;quot; of course immediately disable the kernel&#039;s
line buffering and control character processing on startup to regain full control
over user input - you may notice ctrl+c doesn&#039;t cause the &lt;code&gt;vim&lt;/code&gt; editor to
terminate as batch programs do.&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/pty.png&quot;&gt; &lt;/p&gt;

&lt;p&gt;Upon launching a shell program, its standard input/output are connected to the
terminal emulator through the kernel via a pty, allowing the madness to begin.&lt;/p&gt;

&lt;p&gt;To see what I mean, run &lt;code&gt;script&lt;/code&gt; to start a recursive shell session where input
will be logged to a file called &lt;code&gt;typescript&lt;/code&gt; in the current working directory.
Launch any &#039;graphical&#039; terminal program, exit and ctrl+d to return to your original
shell. Opening &lt;code&gt;typescript&lt;/code&gt; with a reliable text editor you see...
an absolutely incomprehensible mess of seemingly random characters.&lt;/p&gt;

&lt;p&gt;You may have heard of these strings as terminal escape codes, which precisely
reflected my urge after developing a &lt;a href=&quot;https://github.com/Plisp/uncursed&quot; &gt;TUI library&lt;/a&gt;.
These unseen sequences are copied between the terminal emulator and TUI program through the pty,
mediating both user input reporting and &#039;graphical&#039; commands
like &#039;clear the screen&#039; or &#039;set the drawing color to flashing red&#039;.&lt;/p&gt;

&lt;p&gt;Where are these sequences defined? Prepare yourself and run &lt;code&gt;infocmp&lt;/code&gt; in a shell.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;xterm|xterm terminal emulator (X Window System),
        am, bce, km, mc5i, mir, msgr, npc, xenl,
        colors#8, cols#80, it#8, lines#24, pairs#64,
        acsc=``aaffggiijjkkllmmnnooppqqrrssttuuvvwwxxyyzz{{||}}~~,
        bel=^G, blink=\E[5m, bold=\E[1m, cbt=\E[Z, civis=\E[?25l,
        clear=\E[H\E[2J, cnorm=\E[?12l\E[?25h, cr=\r,
        csr=\E[%i%p1%d;%p2%dr, cub=\E[%p1%dD, cub1=^H,
        cud=\E[%p1%dB, cud1=\n, cuf=\E[%p1%dC, cuf1=\E[C,
        cup=\E[%i%p1%d;%p2%dH, cuu=\E[%p1%dA, cuu1=\E[A,
        cvvis=\E[?12;25h, dch=\E[%p1%dP, dch1=\E[P, dim=\E[2m,
        ......&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You might notice some of these sequences were the same codes from &lt;code&gt;script&lt;/code&gt; earlier.
Also note that these sequences are specific to a certain terminal emulator type,
in this case &lt;code&gt;xterm&lt;/code&gt;. There&#039;s a whole directory somewhere filled with repeated
descriptions for dozens of terminal types, most of which you will certainly never need.
In fact, many terminals have outdated terminfo descriptions or lie that
&lt;code&gt;TERM=xterm-256color&lt;/code&gt;, which makes writing a library wrapper
&lt;a href=&quot;https://github.com/neovim/neovim/blob/a0201b6ed37bae594bd0db2804c8ecff09a29e0e/src/nvim/tui/tui.c#L1585&quot; &gt;uniquely painful&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Fortunately you&#039;ve probably got a fun terminal library wrapper so you don&#039;t need
to worry right?&lt;/p&gt;

&lt;p&gt;Well... not quite. Half the keys when modified, and especially mouse events will
simply not be reported by the terminal emulator due to &lt;a href=&quot;https://invisible-island.net/xterm/modified-keys.html&quot; &gt;legacy encoding issues&lt;/a&gt;.
On top of that displaying things is generally still your problem, and the only
graphical primitive available to you is sending text through what&#039;s essentially a pipe.
Because you&#039;re copying text in and out of the kernel, as well as waiting on slow
terminals to parse color control sequences, it&#039;s common to observe screen tearing
if your library &lt;em&gt;coughs and ncurses&lt;/em&gt; fails to optimize output properly.
For those morbidly curious, this involves
insanity such as batch-drawing things with the same color to avoid outputting long
color-changing sequences and minimising movement of the terminal cursor - the only location
where text can be drawn on the screen.&lt;/p&gt;

&lt;p&gt;But there&#039;s more!&lt;/p&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/terminals.png&quot;&gt; &lt;/p&gt;

&lt;p&gt;The concept of a character&#039;s display width is not well defined with terminals,
accustomed to a grid of monospace ascii characters, and so
no terminal emulator in existence can render wide and combining characters
&lt;a href=&quot;https://github.com/Plisp/wcwidth-comparision&quot; &gt;consistently&lt;/a&gt; though alacritty seems
to come close. This reflects another lack of standardization which means no TUI 
can draw emojis in a consistent way.&lt;/p&gt;

&lt;h2&gt;deep breath and conclusion&lt;/h2&gt;

&lt;p&gt;While the shell is handy for opaque textual command pipelines, programs needing
real user interaction should be implemented in something sane like SDL.&lt;/p&gt;
</content> </entry><entry> <link type="text/html" rel="alternate" href="/posts/Editing-abstraction-not-text-updated.html"/> <title>Editing abstraction not text (updated)</title> <published>2021-11-29 10:24:59</published> <updated>2021-11-29 10:24:59</updated> <author> <name>plisp</name> <uri></uri> </author> <content type="html">&lt;p&gt;So I started off writing a &lt;a href=&quot;https://github.com/Plisp/vico&quot; &gt;text editor&lt;/a&gt; that would suit
my needs: being fully extensible via a scripting language &lt;strong&gt;and&lt;/strong&gt; performant.  Along the
way I devised &lt;a href=&quot;https://github.com/Plisp/libst&quot; &gt;an improvement&lt;/a&gt; on the
&lt;a href=&quot;https://en.wikipedia.org/wiki/Piece_table&quot; &gt;piece-table&lt;/a&gt; which significantly outperforms
all existing similar data structures to my knowledge.  There was a small caveat to my
particular implementation - it exploited the fact that codepoint and line number tracking
are not crucial in the backend of a text editor (details in paper), meaning much of the
file did not need to be read with expensive system calls, instead lazily loaded by the
operating system&#039;s virtual memory subsystem.&lt;/p&gt;

&lt;p&gt;Arguably at that point my implementation was not exactly comparable to others since I was
no longer providing the same abstract interface as typical text buffers. But the key
insight is that bytes, codepoints and lines are simply not the units in which we percieve
code.&lt;/p&gt;

&lt;p&gt;When designing a development environment, I think a good premise is that not everything
is text, just as &lt;a href=&quot;https://www.youtube.com/watch?v=9-IWMbJXoLM&quot; &gt;not everything is a file&lt;/a&gt;.&lt;/p&gt;

&lt;!--more--&gt;

&lt;h3&gt;Problems with text editing, bandaid solutions&lt;/h3&gt;

&lt;p&gt;Treating code as a string of bytes leads to worse semantic awareness in tooling and
inevitable efficiency problems beyond text editing, even with things as simple as
&lt;a href=&quot;https://code.visualstudio.com/blogs/2021/09/29/bracket-pair-colorization&quot; &gt;bracket
matching&lt;/a&gt;,
which require knowledge of the source code&#039;s implicit structure, as some parens are part
of strings, comments escaped literals, etc.  Instead, a code editor&#039;s document
representation should reflect semantic structures like variables, blocks and function
definitions, while text remains a secondary format for serialization to disk.&lt;/p&gt;

&lt;p&gt;Tools like tree-sitter and regex lexers which attempt to analyze code as text ultimately
fail when syntax depends on semantics. In the C example below, the correct highlighting
of the variable &lt;code&gt;a&lt;/code&gt; needs to identify that &lt;code&gt;foo&lt;/code&gt; is in fact a type and so the expression
casts &lt;code&gt;(a+3)&lt;/code&gt; to a &lt;code&gt;foo&lt;/code&gt; rather than calling the function &lt;code&gt;foo&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;c typedef int foo; (foo)(a + 3);&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;Of course, complete analysis of code essentially means rewriting a compiler frontend
which parses text and builds a graph of semantic objects, known as an Abstract Syntax
Graph or ASG.  This duplication of effort is unfortunately necessary to build good
tooling as compilers (libclang being an exception, however not incremental enough for use
in an editor) don&#039;t typically expose their internal representation of code. In an &lt;a href=&quot;https://www.youtube.com/watch?v=39wlNRk-nAg&quot; &gt;ideal
world&lt;/a&gt; compilers would produce artifacts
that syntax highlighting, code formatters, linters, completion and &lt;code&gt;ctags&lt;/code&gt; can reuse.&lt;/p&gt;

&lt;p&gt;And to address the elephant in the room - Microsoft&#039;s Language Server Protocol introduces
great friction (asynchronous procedure calls? UTF-16 indices?) for achieving relatively
mundane functionality and is inextensible.  There are two significant problems with
isolating the ASG in a separate process:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Availability - Say you want to determine whether a variable is global in an unfamiliar
codebase.  This doesn&#039;t exist in the protocol and is not trivial to determine, so do you
hack it into the lsp server and client or wait for Microsoft to standardize a new call?&lt;/li&gt;
&lt;li&gt;Granularity - Say you wanted to highlight all direct mutations of a variable in some
function.  This doesn&#039;t exist in the protocol, but could be implemented by calling
&lt;code&gt;DocumentHighlight&lt;/code&gt;, which returns &lt;em&gt;all&lt;/em&gt; references to the symbol in a file and whether
they are read/writes, and trimming the list to the current function body by using a
&lt;code&gt;DocumentSymbol&lt;/code&gt; hierachy. However you&#039;ve asked for &lt;em&gt;every&lt;/em&gt; reference to the symbol,
which is significantly more work than necessary.&lt;/li&gt;
&lt;/ul&gt;

&lt;h3&gt;An incremental IDE&lt;/h3&gt;

&lt;p&gt;If editor scripting could access the code&#039;s syntax tree, the above would be trivial.
However LSP&#039;s capabilities only scratch the surface of possibilities, representing the
lowest common denominator of a multitude of languages. Let&#039;s try a stream of
consciousness...  Given a database of types, function definitions, variables and an AST
it is possible to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;provide scripting of highlighting modes, emphasizing particular variables, mutations
and accurate conventional semantic highlighting of keywords, types, etc.&lt;/li&gt;
&lt;li&gt;incremental static analysis&lt;/li&gt;
&lt;li&gt;augmenting hardcoded snippets, dynamically provide completion of valid control flow constructs&lt;/li&gt;
&lt;li&gt;edit structurally, eliminating syntax errors&lt;/li&gt;
&lt;li&gt;edit alternate visual &#039;projections&#039; of a code model: C like python without extraneous braces and semicolons,
or even scratch (cursed), edit math equations typeset inline with latex, color pickers for rgb values...&lt;/li&gt;
&lt;/ul&gt;

&lt;p align=&quot;center&quot;&gt; &lt;img src=&quot;../static/cpython.png&quot;&gt; &lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;write code generating macros in the scripting language of the editor rather than the
programming language (more on this in future posts)&lt;/li&gt;
&lt;li&gt;execute code in a REPL: live within the editor without waiting for a full recompilation&lt;/li&gt;
&lt;li&gt;track memory allocations, detecting accesses out of bounds and identifying their source without leaving the editor and
running valgrind&lt;/li&gt;
&lt;li&gt;debug by richly inspecting state and directly redefining functions&lt;/li&gt;
&lt;li&gt;generate a control flow graph leading up to a debugger crash, displaying values of
variables involved at each branch (debug printing but automatic) or better:&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Now some of these may be theoretically possible in a modern IDE, but with structural
editing operations that operate on the ASG while keeping it valid (possibly with
&amp;quot;holes&amp;quot;), reindexing is minimised and incrementality is possible, perhaps remedying the
sluggishness common to such tools.&lt;/p&gt;

&lt;h3&gt;Reducing working memory load&lt;/h3&gt;

&lt;p&gt;What&#039;s the point of all this?  It&#039;s important to note that computers once ran binary
machine code, before we moved to assembler, to familiar high-level languages like python,
java, rust to abstract away the low-level concerns peripheral to our mental model of a
program, closing in on the ideal: &lt;code&gt;working memory + screen = complete model of whatever
we&#039;re working on&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;While the abstractions of the programming language are crucial, being the raw materials
comprising a program, our tooling can accessibly display all the invariants intrinsic to
the code, allowing us to find and correct the structural issues undermining the
robustness of our constructions.  In this line of analogy, debugging with breakpoints is
akin to relying on photos taken blindfolded to determine the cause of a building&#039;s
collapse.  Keeping a full view of the relevant component within reach at all times
(especially following error) allows more precious working memory to be devoted to design;
easing implementation and debugging.&lt;/p&gt;

&lt;h3&gt;It&#039;s hard&lt;/h3&gt;

&lt;p&gt;But of course first you need to implement a compiler frontend, an executor, an editor and
make it all scalable. My first thought was a simple enough static language: C (languages
with true macro abstractions tend to be much
&lt;a href=&quot;https://rust-analyzer.github.io/blog/2021/11/21/ides-and-macros.html&quot; &gt;harder&lt;/a&gt; to analyse)
for which I now have a parser, but perhaps also a language could be designed that fully
eliminates the textual redundancy and works with the editing environment to incrementally
analyse program invariants.&lt;/p&gt;

&lt;p&gt;More posts to come!&lt;/p&gt;
</content> </entry><entry> <link type="text/html" rel="alternate" href="/posts/2020-08-15.html"/> <title>2020-08-15</title> <published>2020-08-15 10:23:51</published> <updated>2020-08-15 10:23:51</updated> <author> <name>plisp</name> <uri></uri> </author> <content type="html">&lt;p&gt;Switched from jekyll to coleslaw. Things look much nicer now.
Code highlighting is looking real sexy.&lt;/p&gt;

&lt;!--more--&gt;

&lt;pre&gt;&lt;code&gt;&lt;span class=&quot;code&quot;&gt;&lt;span class=&quot;paren1&quot;&gt;(&lt;span class=&quot;code&quot;&gt;&lt;i&gt;&lt;span class=&quot;symbol&quot;&gt;defvar&lt;/span&gt;&lt;/i&gt; &lt;span class=&quot;special&quot;&gt;*my-fasldir*&lt;/span&gt; &lt;span class=&quot;string&quot;&gt;&quot;fasl/&quot;&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;

&lt;span class=&quot;paren1&quot;&gt;(&lt;span class=&quot;code&quot;&gt;&lt;i&gt;&lt;span class=&quot;symbol&quot;&gt;defun&lt;/span&gt;&lt;/i&gt; my-sly-compile-file &lt;span class=&quot;paren2&quot;&gt;(&lt;span class=&quot;code&quot;&gt;&lt;/span&gt;)&lt;/span&gt;
  &lt;span class=&quot;paren2&quot;&gt;(&lt;span class=&quot;code&quot;&gt;interactive&lt;/span&gt;)&lt;/span&gt;
  &lt;span class=&quot;paren2&quot;&gt;(&lt;span class=&quot;code&quot;&gt;&lt;i&gt;&lt;span class=&quot;symbol&quot;&gt;let*&lt;/span&gt;&lt;/i&gt; &lt;span class=&quot;paren3&quot;&gt;(&lt;span class=&quot;code&quot;&gt;&lt;span class=&quot;paren4&quot;&gt;(&lt;span class=&quot;code&quot;&gt;rootdir &lt;span class=&quot;paren5&quot;&gt;(&lt;span class=&quot;code&quot;&gt;projectile-project-root&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;
         &lt;span class=&quot;paren4&quot;&gt;(&lt;span class=&quot;code&quot;&gt;fasldir &lt;span class=&quot;paren5&quot;&gt;(&lt;span class=&quot;code&quot;&gt;concat &lt;span class=&quot;paren6&quot;&gt;(&lt;span class=&quot;code&quot;&gt;projectile-project-root&lt;/span&gt;)&lt;/span&gt; &lt;span class=&quot;special&quot;&gt;*my-fasldir*&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;
         &lt;span class=&quot;paren4&quot;&gt;(&lt;span class=&quot;code&quot;&gt;relative-dir &lt;span class=&quot;paren5&quot;&gt;(&lt;span class=&quot;code&quot;&gt;string-trim-right
                        &lt;span class=&quot;paren6&quot;&gt;(&lt;span class=&quot;code&quot;&gt;substring &lt;span class=&quot;paren1&quot;&gt;(&lt;span class=&quot;code&quot;&gt;buffer-file-name &lt;span class=&quot;paren2&quot;&gt;(&lt;span class=&quot;code&quot;&gt;current-buffer&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt; &lt;span class=&quot;paren1&quot;&gt;(&lt;span class=&quot;code&quot;&gt;length rootdir&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;
                        &lt;span class=&quot;string&quot;&gt;&quot;[^/]+&quot;&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;
         &lt;span class=&quot;paren4&quot;&gt;(&lt;span class=&quot;code&quot;&gt;file-fasl-dir &lt;span class=&quot;paren5&quot;&gt;(&lt;span class=&quot;code&quot;&gt;concat fasldir relative-dir&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;
    &lt;span class=&quot;paren3&quot;&gt;(&lt;span class=&quot;code&quot;&gt;make-directory file-fasl-dir t&lt;/span&gt;)&lt;/span&gt;
    &lt;span class=&quot;paren3&quot;&gt;(&lt;span class=&quot;code&quot;&gt;&lt;i&gt;&lt;span class=&quot;symbol&quot;&gt;setq&lt;/span&gt;&lt;/i&gt; sly-compile-file-options &lt;span class=&quot;paren4&quot;&gt;(&lt;span class=&quot;code&quot;&gt;list &lt;span class=&quot;keyword&quot;&gt;:fasl-directory&lt;/span&gt; file-fasl-dir&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;
    &lt;span class=&quot;paren3&quot;&gt;(&lt;span class=&quot;code&quot;&gt;sly-compile-file&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;)&lt;/span&gt;

&lt;span class=&quot;comment&quot;&gt;; if using use-package do
&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;; :bind (:map sly-editing-mode-map (&quot;C-c C-k&quot; . #&#039;my-sly-compile-file))
&lt;/span&gt;&lt;span class=&quot;comment&quot;&gt;; otherwise
&lt;/span&gt;&lt;span class=&quot;paren1&quot;&gt;(&lt;span class=&quot;code&quot;&gt;bind-key &lt;span class=&quot;string&quot;&gt;&quot;C-c C-k&quot;&lt;/span&gt; #&#039;my-sly-compile-file sly-editing-mode-map&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The scope highlighting is not particularly useful at the moment as finding colors that don&#039;t clash with solarized is a real challenge.&lt;/p&gt;
</content> </entry> </feed>